--- git status ---
On branch main
Your branch is up to date with 'origin/main'.

Changes not staged for commit:
  (use "git add <file>..." to update what will be committed)
  (use "git restore <file>..." to discard changes in working directory)
	modified:   src/go2_muscle_task/actuators/muscle_model.py
	modified:   src/go2_muscle_task/config/agents/rsl_rl_ppo_cfg.py
	modified:   src/go2_muscle_task/mdp/actions/joint_actions.py
	modified:   src/train.py

Untracked files:
  (use "git add <file>..." to include in what will be committed)
	src/logs/
	src/outputs/2024-11-06/15-46-10/
	src/outputs/2024-11-06/18-44-17/
	src/outputs/2024-11-06/18-46-29/
	src/outputs/2024-11-06/18-47-08/
	src/outputs/2024-11-06/19-10-31/
	src/outputs/2024-11-06/19-11-22/
	src/outputs/2024-11-06/19-11-49/
	src/outputs/2024-11-06/19-26-03/
	src/outputs/2024-11-06/19-27-21/
	src/outputs/2024-11-06/19-28-11/
	src/outputs/2024-11-06/19-29-00/
	src/outputs/2024-11-06/19-29-39/
	src/outputs/2024-11-06/19-30-23/
	src/outputs/2024-11-06/19-45-03/
	src/outputs/2024-11-06/19-50-41/
	src/outputs/2024-11-06/19-52-56/
	src/outputs/2024-11-06/19-56-19/
	src/outputs/2024-11-06/20-10-15/
	src/outputs/2024-11-06/20-14-52/
	src/outputs/2024-11-06/20-15-24/
	src/outputs/2024-11-06/20-21-30/
	src/outputs/2024-11-06/20-21-51/
	src/outputs/2024-11-06/20-24-02/
	src/outputs/2024-11-06/20-25-22/
	src/outputs/2024-11-06/20-26-16/
	src/outputs/2024-11-06/20-26-52/
	src/outputs/2024-11-06/20-28-46/
	src/outputs/2024-11-06/20-35-01/
	src/outputs/2024-11-06/21-16-08/

no changes added to commit (use "git add" and/or "git commit -a") 


--- git diff ---
diff --git a/src/go2_muscle_task/actuators/muscle_model.py b/src/go2_muscle_task/actuators/muscle_model.py
index 3fab509..a8b5264 100755
--- a/src/go2_muscle_task/actuators/muscle_model.py
+++ b/src/go2_muscle_task/actuators/muscle_model.py
@@ -12,7 +12,7 @@ torch.set_default_dtype(torch.float32)
 class MuscleModel:
     def __init__(self, muscle_params, action_tensor, nenvironments, options):
         self.device = "cuda"
-        self.nactioncount = 16
+        self.nactioncount = 24
         self.nenvironments = nenvironments
 
         for k, v in muscle_params.items():
@@ -189,6 +189,7 @@ class MuscleModel:
         velocity = lce_dot
 
         eff_vel = torch.div(velocity, self.vmax)
+
         c_result = torch.zeros_like(
             eff_vel,
             dtype=torch.float32,
@@ -336,7 +337,6 @@ class MuscleModel:
         FP = self.FP(lce_tensor)
 
         self.force_tensor = torch.add(torch.mul(torch.mul(FL, FV), self.activation_tensor), FP)
-        # peak foce will always be the same for solo8/12 and does not need a check if the value was set correctly in .xml of mujoco
         # peak_force = self.get_peak_force(actuator_velocity)
         F = torch.mul(self.force_tensor, self.peak_force)
         torque = F * self.moment
@@ -404,11 +404,11 @@ class MuscleModel:
             # compute moments
             moment = self.compute_moment(actions, actuator_vel, self.lce_1_tensor, self.lce_2_tensor)
 
-            if self.validation_experiment_muscle_action_change:
-                moment = self.datastorage.visualize_max_dof_pos(moment)
+            # if self.validation_experiment_muscle_action_change:
+            #     moment = self.datastorage.visualize_max_dof_pos(moment)
 
-            if self.storedata:
-                self.datastorage.joint_positions.append(actuator_pos.tolist()[0])
-                self.datastorage.joint_velocities.append(actuator_vel.tolist()[0])
-                self.datastorage.joint_torques.append(moment.tolist()[0])
+            # if self.storedata:
+            #     self.datastorage.joint_positions.append(actuator_pos.tolist()[0])
+            #     self.datastorage.joint_velocities.append(actuator_vel.tolist()[0])
+            #     self.datastorage.joint_torques.append(moment.tolist()[0])
             return moment
diff --git a/src/go2_muscle_task/config/agents/rsl_rl_ppo_cfg.py b/src/go2_muscle_task/config/agents/rsl_rl_ppo_cfg.py
index 75006da..9566907 100644
--- a/src/go2_muscle_task/config/agents/rsl_rl_ppo_cfg.py
+++ b/src/go2_muscle_task/config/agents/rsl_rl_ppo_cfg.py
@@ -8,12 +8,15 @@ from omni.isaac.lab_tasks.utils.wrappers.rsl_rl import (
 
 @configclass
 class Go2MuscleRunnerCfg(RslRlOnPolicyRunnerCfg):
+    num_steps_per_env = 24
     max_iterations = 300
+    save_interval = 50
     experiment_name = "unitree_go2_muscle"
+    empirical_normalization = False
     policy=RslRlPpoActorCriticCfg(
         init_noise_std=1.0,
-        actor_hidden_dims = [128, 128, 128],
-        critic_hidden_dims = [128, 128, 128],
+        actor_hidden_dims = [512, 256, 128],
+        critic_hidden_dims = [512, 256, 128],
         activation="elu"
     )
     algorithm=RslRlPpoAlgorithmCfg(
diff --git a/src/go2_muscle_task/mdp/actions/joint_actions.py b/src/go2_muscle_task/mdp/actions/joint_actions.py
index 4d6ec3a..0c9a519 100644
--- a/src/go2_muscle_task/mdp/actions/joint_actions.py
+++ b/src/go2_muscle_task/mdp/actions/joint_actions.py
@@ -19,16 +19,17 @@ class MuscleJointAction(JointAction):
         super().__init__(cfg, env)
 
         muscle_params = {
-            "l_min":0.24,
-            "l_max":1.53,
+            "lmin":0.24,
+            "lmax":1.53,
             "fvmax": 1.38,
             "fpmax": 1.76,
             "lce_min": 0.74,
             "lce_max": 0.94,
             "phi_min": -3.14,
             "phi_max": 3.14,
-            #TODO pierre wegen parameter fragen
-            "eps": 0.0
+            "vmax": 30.0, # TODO pierre fragen, ob das das ricthige ist (taken from unitre.py UNITREE_GO2_CFG)
+            "peak_force": 45.0,
+            "eps": 10e-5 # eps is just a smal number for numerical purpouses
         }
 
         self.muscles = MuscleModel(muscle_params=muscle_params,
@@ -37,8 +38,8 @@ class MuscleJointAction(JointAction):
                                    options=None)
 
     def apply_actions(self):
-        self.muscles.compute_torques(self._asset.data.joint_pos, self._asset.data.joint_acc)
-        self._asset.set_joint_effort_target(self.processed_actions, joint_ids=self._joint_ids)
+        torques = self.muscles.compute_torques(self._asset.data.joint_pos, self._asset.data.joint_vel, self._processed_actions)
+        self._asset.set_joint_effort_target(torques, joint_ids=self._joint_ids)
 
     @property
     def action_dim(self):
diff --git a/src/train.py b/src/train.py
index 5fc6fb3..a4b807f 100644
--- a/src/train.py
+++ b/src/train.py
@@ -126,8 +126,13 @@ def main(env_cfg: ManagerBasedRLEnvCfg | DirectRLEnvCfg | DirectMARLEnvCfg, agen
     # wrap around environment for rsl-rl
     env = RslRlVecEnvWrapper(env)
 
+    print("AGENT", agent_cfg.to_dict())
+
     # create runner from rsl-rl
     runner = OnPolicyRunner(env, agent_cfg.to_dict(), log_dir=log_dir, device=agent_cfg.device)
+
+    print("REACHED HERE")
+
     # write git state to logs
     runner.add_git_repo_to_log(__file__)
     # load the checkpoint
@@ -136,6 +141,7 @@ def main(env_cfg: ManagerBasedRLEnvCfg | DirectRLEnvCfg | DirectMARLEnvCfg, agen
         # load previously trained model
         runner.load(resume_path)
 
+
     # dump the configuration into log-directory
     dump_yaml(os.path.join(log_dir, "params", "env.yaml"), env_cfg)
     dump_yaml(os.path.join(log_dir, "params", "agent.yaml"), agent_cfg)